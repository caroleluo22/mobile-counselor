# **AI Admissions Copilot â€” Investor Technical Q&A Playbook**

---

## **1. â€œIsnâ€™t this just a wrapper around ChatGPT?â€**

**Best answer:**

> No. ChatGPT is one component, not the product.
> The value comes from domain-specific grounding, multi-agent orchestration, and browser-level execution.

Then explain briefly:

* We maintain a curated admissions knowledge base grounded in official policies.
* Specialized agents handle strategy, essays, policy interpretation, and execution.
* The browser extension allows the system to act inside real admissions portals.

**Close with:**

> Generic chatbots give advice. Our system completes workflows.

---

## **2. â€œWhy do you need a RAG system if admissions info is public?â€**

**Best answer:**

> Public does not mean reliable or current. Admissions policies change yearly and vary by program, citizenship, and degree level.

Key points:

* LLMs rely on training snapshots and may be outdated.
* RAG ensures answers are grounded in the latest official sources.
* It reduces hallucinations and allows us to show citations.

**Investor framing:**

> For a high-stakes decision system, accuracy and trust are non-negotiable.

---

## **3. â€œWhatâ€™s your real technical moat?â€**

**Best answer:**

> The moat is execution + domain intelligence, not the model itself.

Break it down:

1. Browser extension that executes inside real portals
2. Structured admissions knowledge base
3. Multi-agent orchestration
4. Continuous feedback loop from real user workflows

**Close with:**

> This is infrastructure, not prompts.

---

## **4. â€œHow hard is the browser extension to build and maintain?â€**

**Best answer:**

> Technically challenging, but very defensible.

Explain:

* We do not hard-code full portals.
* We maintain abstract â€œportal schemasâ€ and field mappings.
* Autofill requires user confirmation â€” no blind automation.
* Extension logic is reusable across platforms.

**Signal maturity:**

> This is exactly why itâ€™s a moat â€” itâ€™s painful but valuable.

---

## **5. â€œHow do you prevent hallucinations or bad advice?â€**

**Best answer:**

> We constrain the AI instead of trusting it blindly.

Mechanisms:

* Retrieval-grounded prompts
* Explicit instructions to rely only on provided sources
* Structured JSON outputs
* Warnings when data is missing or ambiguous
* User review before execution

**Key phrase:**

> The system is designed to say â€œI donâ€™t knowâ€ when appropriate.

---

## **6. â€œHow do you keep the knowledge base up to date?â€**

**Best answer:**

> We control the source of truth.

Explain:

* Scheduled ingestion of official admissions pages
* Manual overrides for high-impact schools
* Extension can flag discrepancies when live pages change
* Versioned knowledge entries by admissions cycle

**Investor reassurance:**

> Updating policies is a data operation, not a product rebuild.

---

## **7. â€œWhat happens when universities redesign their websites?â€**

**Best answer:**

> Website changes are expected, and the system is designed for it.

Explain:

* We rely on semantic extraction, not brittle selectors.
* The extension can fall back to explanation mode even if autofill is disabled.
* Field mappings are updated incrementally.

**Confidence signal:**

> This is a maintenance cost, not an existential risk.

---

## **8. â€œHow do you handle privacy and sensitive student data?â€**

**Best answer:**

> Student data is treated as high-sensitivity educational data.

Mention:

* Encrypted storage and transport
* Role-based access control
* No automatic submission without user approval
* Audit logs for AI actions

**Close with:**

> We design for parent-level trust, not just student convenience.

---

## **9. â€œHow do AI costs scale as usage grows?â€**

**Best answer:**

> AI costs scale sub-linearly with users.

Explain:

* Reuse of embeddings and retrieval results
* Caching of common explanations
* Short, structured prompts
* Most users follow similar workflows

**Investor-friendly line:**

> Margins expand as the system learns.

---

## **10. â€œWhatâ€™s the failure mode of the system?â€**

**Best answer:**

> The system degrades gracefully.

Examples:

* If data is missing â†’ explain uncertainty
* If autofill is risky â†’ switch to guidance-only mode
* If policies conflict â†’ flag and ask user to verify

**Key framing:**

> The AI never acts without user visibility.

---

## **11. â€œCould OpenAI or another platform just build this?â€**

**Best answer:**

> Large model providers donâ€™t specialize in domain execution.

Explain:

* They build general models, not admissions infrastructure.
* The value is in:

  * domain curation
  * workflow design
  * browser execution
  * distribution into schools

**Close with:**

> Weâ€™re closer to TurboTax than to a chatbot.

---

## **12. â€œWhatâ€™s the hardest technical problem youâ€™re solving?â€**

**Best answer:**

> Turning unstructured admissions chaos into structured, executable workflows.

Explain:

* Policy interpretation
* Edge cases across programs and countries
* Safe automation
* Trust-worthy AI outputs

**Investor signal:**

> This is a systems problem, not a prompt problem.

---

## **13. â€œWhat would break this business technically?â€**

**Best answer:**

> If admissions became fully standardized and machine-readable overnight.

Then smile and say:

> The opposite trend is happening.

---

## **14. â€œWhat do you build in-house vs rely on vendors for?â€**

**Best answer:**

> We rely on vendors for base models and infrastructure, and build everything workflow-critical in-house.

In-house:

* knowledge curation
* agent orchestration
* autofill logic
* portal schemas
* UX & trust mechanisms

---

## **15. â€œWhat convinces you this can replace consultants?â€**

**Best answer:**

> Consultants spend most of their time explaining policies, managing timelines, and formatting applications â€” all of which software does better.

Close with:

> Human judgment remains, but human labor does not need to scale.

---

# ðŸ§  How to use this in meetings

* Donâ€™t over-explain
* Answer in **30â€“60 seconds**
* Anchor back to **trust, execution, and scalability**
* Always end with a **confident framing sentence**

---
